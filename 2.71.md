# 2.71

## Question

Suppose we have a Huffman tree for an alphabet of $n$ symbols, and that the relative frequencies of the symbols are $1, 2, 4, ..., 2^{n-1}$. Sketch the tree for $n=5$; for $n=10$. In such a tree (for general $n$) how many bits are required to encode the most frequent symbol? the least frequent symbol?

## Answer

Huffman reductions for $2^n$-frequency data yield a linked list structure:

```
> ((1 1) (2 2) (4 4) (8 8) (16 16))

       (31) <-- weight
        / \
     (15)  16
      / \
    (7)  8
    / \
  (3)  4
  / \
 1   2
````

This is inefficient because the algorithm leaves many shorter code slots empty.

| Symbol | Space | Code |
|---|---|---|
Most frequent | $1$ bit | `(1)` |
Least frequent | $\log n$ bits | `(0 ... 0)` (repeated $\log n$ times) |

By contrast, rank-ordering the weights yield a balanced tree:

```
> ((1 1) (2 2) (4 3) (8 4) (16 5))

   (15) <-- weight
    / \
  (6)  ---(9)
  / \     / \
 4  (3)  8  16
    / \
   1   2
````

Now we reach the least frequent symbol in 3 bits instead of 4 bits (`010` vs. `0000`), yielding a 25% bit reduction.
